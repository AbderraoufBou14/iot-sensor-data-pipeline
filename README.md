# Pipeline de donnÃ©es streaming temps rÃ©el â€“ IoT Smart Building (Kafka, Spark Streaming, S3 Datalake, FastAPI)

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)
![Kafka](https://img.shields.io/badge/Kafka-Streaming-231F20?logo=apachekafka)
![Spark](https://img.shields.io/badge/Spark-Structured%20Streaming-E25A1C?logo=apachespark)
![FastAPI](https://img.shields.io/badge/FastAPI-API-009688?logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Containerization-0db7ed?logo=docker)
![S3](https://img.shields.io/badge/S3-Data%20Lake-569A31?logo=amazon-aws)
![Parquet](https://img.shields.io/badge/Parquet-Columnar-0E6FBF?logo=apache)
![Scikit-learn](https://img.shields.io/badge/ML-Scikit--Learn-F7931E?logo=scikitlearn)
![Git](https://img.shields.io/badge/Git-Version%20Control-F05032?logo=git&logoColor=white)

---

## ğŸ“Š DonnÃ©es utilisÃ©es

- Issues du *Smart Building System Dataset* (UC Berkeley).  
- 255 sÃ©ries temporelles provenant de capteurs IoT dans 51 salles.  
- 5 types de mesures : tempÃ©rature, humiditÃ©, COâ‚‚, luminositÃ©, mouvement PIR.  
- FrÃ©quence dâ€™Ã©chantillonnage : 5 Ã  10 secondes selon le capteur.  
- PÃ©riode couverte : 23 au 31 aoÃ»t 2013.

**Source Kaggle :**  
https://www.kaggle.com/datasets/mdelfavero/smart-building-system

---

## ğŸ§¬ Description pipeline :

- Le producer lit automatiquement les CSV S3 de chaque capteur et room, rejoue les mesures en flux continu, puis les envoie dans les topics Kafka en respectant soit un dÃ©bit fixe (rate), soit les intervalles rÃ©els du dataset (timewarp), parametres a modifer depuis le .env
- Le consumer Spark streaming lit les messages Kafka en Json et les Ã©crit en format parquet sur la couche bronze, partitionnÃ©e par (date, room et type de capteur. Un checkpoint garantit la reprise du streaming en cas des pannes.
- Un premier job spark enrichit les donnÃ©es Bronze (room, sensor, qualitÃ©), calcule event_date et les Ã©crit en Parquet. Le rÃ©sultat est une couche Silver propre, partitionÃ© par date , rapide et prete pour l'analyse.
- Un deuxiÃ¨me job Spark agrÃ¨ge les donnÃ©es Silver en KPIs horaires et journaliÃ¨res par room, et les sauvegarde en tables Parquet prÃªtes Ã  lâ€™usage sur la couche Gold. Airflow orchestre son exÃ©cution quotidienne.
---

## ğŸ—ï¸ Architecture globale du pipeline

```mermaid
flowchart LR

    CSV[CSV capteurs]
    Producer[Replay Producer]

    Kafka[(Kafka Broker)]

    Consumer{{Spark Consumer Bronze}}

    Bronze[(Bronze Layer)]

    SilverJob{{Spark Silver Job}}

    Silver[(Silver Layer)]

    GoldJob{{Spark Gold Job}}

    Gold[(Gold Layer)]

    API[FastAPI API]

    CSV --> Producer --> |Json| Kafka --> Consumer -->|Parquet| Bronze --> SilverJob -->|Parquet| Silver --> GoldJob -->|Parquet| Gold
    Silver --> API
```
---

## Captures dâ€™Ã©cran

---
## ğŸ‘¨â€ğŸ’» Auteur

**Abderraouf Boukarma**  

ğŸ“§ **Email :** [boukarmaabderraouf@gmail.com](mailto:boukarma.abderraouf@gmail.com)  
ğŸŒ **LinkedIn :** [linkedin.com/in/abderraouf-boukarma](https://www.linkedin.com/in/abderraouf-boukarma)  
ğŸ’» **GitHub :** [github.com/AbderraoufBou14](https://github.com/AbderraoufBou14)
